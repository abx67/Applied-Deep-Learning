{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fan_tumor_detect.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abx67/Applied-Deep-Learning/blob/master/fan_tumor_detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wrgl42gH4Mgh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook is used to localize tumor area for `tumor_091.tif`.  "
      ]
    },
    {
      "metadata": {
        "id": "K9aBDiAkL5JM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Done(12.19)----------> Improvement:\n",
        "1. `kp_image.img_to_array()` preprocess images more efficiently. \n",
        "2. `np.asarray()` would not copy array like `np.array()`.\n",
        "3. `model`: VGG16+global pooling 2D instead of flatten layer. \n",
        "4. `label2mask`: change i with j because width and height issue.\n",
        "\n",
        "---\n",
        "\n",
        "TODO(12.19):\n",
        "1. **find tissue areas improvement**. (do not use too many non-tissue areas so as to improve performance.)\n",
        "2. Evaluation: check accuracy! \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GQvI12OK6-tP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xydGWdKs6bJ5",
        "colab_type": "code",
        "outputId": "2bf650e0-29f8-4f5c-b1b5-da688aaa152f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "# Install the OpenSlide C library and Python bindings\n",
        "!apt-get install openslide-tools\n",
        "!pip install openslide-python"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "openslide-tools is already the newest version (3.4.1+dfsg-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
            "Requirement already satisfied: openslide-python in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from openslide-python) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->openslide-python) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9xLCkPxn6jzB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from openslide import open_slide, __library_version__ as openslide_version\n",
        "import os\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2gray\n",
        "from tensorflow.python.keras.preprocessing import image as kp_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TDXPa2Qs6Vyg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 0: Download Slide and Show Details"
      ]
    },
    {
      "metadata": {
        "id": "c4Q1jV2F7aC5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "slide_path = 'tumor_091.tif'\n",
        "tumor_mask_path = 'tumor_091_mask.tif'\n",
        "\n",
        "slide_url = 'https://storage.googleapis.com/applied-dl/%s' % slide_path\n",
        "mask_url = 'https://storage.googleapis.com/applied-dl/%s' % tumor_mask_path\n",
        "\n",
        "# Download the whole slide image\n",
        "if not os.path.exists(slide_path):\n",
        "  !curl -O $slide_url\n",
        "\n",
        "# Download the tumor mask\n",
        "if not os.path.exists(tumor_mask_path):\n",
        "  !curl -O $mask_url"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mIxvb2Md-YXe",
        "colab_type": "code",
        "outputId": "751e5724-e14e-4bd0-cdf5-c6f90ea771b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "slide = open_slide(slide_path)\n",
        "print (\"Read WSI from %s with width: %d, height: %d\" % (slide_path, \n",
        "                                                        slide.level_dimensions[0][0], \n",
        "                                                        slide.level_dimensions[0][1]))\n",
        "\n",
        "tumor_mask = open_slide(tumor_mask_path)\n",
        "print (\"Read tumor mask from %s\" % (tumor_mask_path))\n",
        "\n",
        "print(\"Slide includes %d levels\", len(slide.level_dimensions))\n",
        "for i in range(len(slide.level_dimensions)):\n",
        "    print(\"Level %d, dimensions: %s downsample factor %d\" % (i, \n",
        "                                                             slide.level_dimensions[i], \n",
        "                                                             slide.level_downsamples[i]))\n",
        "    assert tumor_mask.level_dimensions[i][0] == slide.level_dimensions[i][0]\n",
        "    assert tumor_mask.level_dimensions[i][1] == slide.level_dimensions[i][1]\n",
        "\n",
        "# Verify downsampling works as expected\n",
        "width, height = slide.level_dimensions[7]\n",
        "assert width * slide.level_downsamples[7] == slide.level_dimensions[0][0]\n",
        "assert height * slide.level_downsamples[7] == slide.level_dimensions[0][1]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read WSI from tumor_091.tif with width: 61440, height: 53760\n",
            "Read tumor mask from tumor_091_mask.tif\n",
            "Slide includes %d levels 8\n",
            "Level 0, dimensions: (61440, 53760) downsample factor 1\n",
            "Level 1, dimensions: (30720, 26880) downsample factor 2\n",
            "Level 2, dimensions: (15360, 13440) downsample factor 4\n",
            "Level 3, dimensions: (7680, 6720) downsample factor 8\n",
            "Level 4, dimensions: (3840, 3360) downsample factor 16\n",
            "Level 5, dimensions: (1920, 1680) downsample factor 32\n",
            "Level 6, dimensions: (960, 840) downsample factor 64\n",
            "Level 7, dimensions: (480, 420) downsample factor 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6xY4OamaNH7o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 1: Read Slide and Preprocess Data"
      ]
    },
    {
      "metadata": {
        "id": "HPgd2tKB-xfW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_slide(slide, x, y, level, width, height, as_float=False):\n",
        "    im = slide.read_region((x,y), level, (width, height))\n",
        "    im = im.convert('RGB') # drop the alpha channel\n",
        "    return im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "weIvOKHke5uU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_aug(x):\n",
        "  \n",
        "  #rotate 4 directions and left-right flip\n",
        "  x1 = np.rot90(x,k=1)\n",
        "  x2 = np.rot90(x1,k=1)\n",
        "  x3 = np.rot90(x2,k=1)\n",
        "  x4 = np.rot90(x3,k=1)\n",
        "  x5 = x1[:, ::-1]\n",
        "  x6 = x2[:,::-1]\n",
        "  x7 = x3[:,::-1]\n",
        "  x8 = x4[:,::-1]\n",
        "  x_new= [x1,x2,x3,x4,x5,x6,x7,x8]\n",
        "  \n",
        "  return x_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EHmhAVIJuOlc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Version 1.0: save images to disk\n",
        "# def data_preprocess(slide, tumor_mask, level, window_size=(299,299),\n",
        "#                            center_size=(128,128),stride=128):\n",
        "  \n",
        "#   if not os.path.exists('train'): \n",
        "#     os.mkdir('train')\n",
        "#   if not os.path.exists('train/tumor'): \n",
        "#     os.mkdir('train/tumor')\n",
        "#   if not os.path.exists('train/normal'):\n",
        "#     os.mkdir('train/normal')\n",
        "  \n",
        "#   factor = int(slide.level_downsamples[level])\n",
        "#   tumor_count = 1\n",
        "#   normal_count = 1\n",
        "#   x_step = (window_size[0]-center_size[0])//2\n",
        "#   y_step = (window_size[1]-center_size[1])//2\n",
        "#   imgs0 = []\n",
        "#   imgs1 = []\n",
        "  \n",
        "#   for i in range(0, slide.level_dimensions[level][0]-window_size[0], stride):  #width\n",
        "#     for j in range(0, slide.level_dimensions[level][1]-window_size[1], stride):   #height\n",
        "#       slide_img = read_slide(slide, i*factor, j*factor, level, window_size[0], window_size[1], as_float=False)\n",
        "#       mask_img = read_slide(tumor_mask, (i+x_step)*factor, (j+y_step)*factor, level, center_size[0], center_size[1], as_float=False)\n",
        "#       if np.sum(mask_img)==0:   #normal\n",
        "#         #slide_img.save(\"train/normal/%d.jpg\" % normal_count)\n",
        "#         #normal_count += 1\n",
        "#         if np.random.uniform(size=1)>0.6:\n",
        "#           imgs0.append(kp_image.img_to_array(slide_img)/255)   #np.asarray?\n",
        "#           #labels.append(0.)\n",
        "#       elif np.sum(mask_img)!=0: #tumor\n",
        "#         slide_img.save(\"train/tumor/%d.jpg\" % tumor_count)\n",
        "#         tumor_count += 1\n",
        "#         imgs1 += data_aug(kp_image.img_to_array(slide_img)/255)\n",
        "        \n",
        "#   imgs = np.concatenate((np.asarray(imgs0),np.asarray(imgs1)))\n",
        "#   labels = np.append(np.repeat(0.,len(imgs0)),np.repeat(1.,len(imgs1)))\n",
        "#   ind = [i for i in range(labels.shape[0])]\n",
        "#   np.random.shuffle(ind)\n",
        "  \n",
        "#   return imgs[ind], labels[ind]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rq4sZ04E0bx_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Version 2.0\n",
        "def data_preprocess(slide, tumor_mask, level, window_size=(299,299),\n",
        "                           center_size=(128,128),stride=128):\n",
        "  \n",
        "  factor = int(slide.level_downsamples[level])\n",
        "  tumor_count = 1\n",
        "  normal_count = 1\n",
        "  x_step = (window_size[0]-center_size[0])//2\n",
        "  y_step = (window_size[1]-center_size[1])//2\n",
        "  imgs0 = []\n",
        "  imgs1 = []\n",
        "  \n",
        "  for i in range(0, slide.level_dimensions[level][0]-window_size[0], stride):  \n",
        "    for j in range(0, slide.level_dimensions[level][1]-window_size[1], stride): \n",
        "      slide_img = read_slide(slide, i*factor, j*factor, level, window_size[0], window_size[1], as_float=False)\n",
        "      mask_img = read_slide(tumor_mask, (i+x_step)*factor, (j+y_step)*factor, level, center_size[0], center_size[1], as_float=False)\n",
        "      if np.sum(mask_img)==0:   #normal\n",
        "        if np.random.uniform(size=1)>0.75: #0.75 has to be tuned each time when we change the size!\n",
        "          imgs0.append(kp_image.img_to_array(slide_img)/255)  \n",
        "      elif np.sum(mask_img)!=0: #tumor\n",
        "        imgs1 += data_aug(kp_image.img_to_array(slide_img)/255)\n",
        "        \n",
        "  imgs = np.concatenate((np.asarray(imgs0),np.asarray(imgs1)))\n",
        "  labels = np.append(np.repeat(0.,len(imgs0)),np.repeat(1.,len(imgs1)))\n",
        "  ind = [i for i in range(labels.shape[0])]\n",
        "  np.random.shuffle(ind)\n",
        "  \n",
        "  return imgs[ind], labels[ind]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "io0P6kIBdGEZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "window_size=(80,80)\n",
        "center_size=(50,50)\n",
        "stride=50\n",
        "level=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cs0wlqBgFAyx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "patches, labels= data_preprocess(slide, tumor_mask, level=3, window_size=window_size,\n",
        "                           center_size=center_size,stride=stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rtojwj50m3yc",
        "colab_type": "code",
        "outputId": "c25f6f55-49fb-4f1f-fc60-fa425fde7fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.unique(labels,return_counts=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0., 1.]), array([5044, 3376]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "8QehlpGUNttn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Train a Model"
      ]
    },
    {
      "metadata": {
        "id": "1cJRI1Y7PGMh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.applications.VGG16(input_shape=(299, 299, 3),include_top=False)\n",
        "model.trainable = False\n",
        "x = model.output\n",
        "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "predictions = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_baseline = tf.keras.models.Model(inputs = model.input, outputs = predictions)\n",
        "model_baseline.compile(loss =\"binary_crossentropy\",\n",
        "                       optimizer = tf.train.RMSPropOptimizer(learning_rate=0.0001),\n",
        "                       metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v5xYVQkZZkWn",
        "colab_type": "code",
        "outputId": "18eea0ef-e112-4cbe-c61b-fc6a2e141876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1578
        }
      },
      "cell_type": "code",
      "source": [
        "model_baseline.fit(patches,labels,epochs=10,batch_size=32,validation_split=0.25)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "198/198 [==============================] - 48s 242ms/step - loss: 0.3887 - acc: 0.8067 - val_loss: 0.2086 - val_acc: 0.9093\n",
            "Epoch 2/10\n",
            "198/198 [==============================] - 44s 222ms/step - loss: 0.2197 - acc: 0.9012 - val_loss: 0.1285 - val_acc: 0.9430\n",
            "Epoch 3/10\n",
            "198/198 [==============================] - 44s 221ms/step - loss: 0.1800 - acc: 0.9249 - val_loss: 0.1075 - val_acc: 0.9530\n",
            "Epoch 4/10\n",
            "198/198 [==============================] - 44s 221ms/step - loss: 0.1302 - acc: 0.9501 - val_loss: 0.0983 - val_acc: 0.9582\n",
            "Epoch 5/10\n",
            "198/198 [==============================] - 44s 220ms/step - loss: 0.1114 - acc: 0.9640 - val_loss: 0.1375 - val_acc: 0.9515\n",
            "Epoch 6/10\n",
            "198/198 [==============================] - 44s 220ms/step - loss: 0.0931 - acc: 0.9706 - val_loss: 0.0823 - val_acc: 0.9734\n",
            "Epoch 7/10\n",
            "164/198 [=======================>......] - ETA: 6s - loss: 0.0872 - acc: 0.9724"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-484276e0ee50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_baseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1612\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1615\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m       return training_distributed.fit_loop(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, class_weight, val_inputs, val_targets, val_sample_weights, batch_size, epochs, verbose, callbacks, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    703\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m           \u001b[0mdo_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m           batch_size=batch_size)\n\u001b[0m\u001b[1;32m    706\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36miterator_fit_loop\u001b[0;34m(model, inputs, class_weight, steps_per_epoch, epoch_logs, val_inputs, val_targets, val_sample_weights, epochs, verbose, callbacks, validation_steps, do_validation, batch_size)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# Train model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     outs, loss, loss_metrics, masks = _process_single_batch(\n\u001b[0;32m--> 251\u001b[0;31m         model, x, y, sample_weights=sample_weights, training=True)\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, sample_weights, training)\u001b[0m\n\u001b[1;32m    519\u001b[0m                         'compiling the model.')\n\u001b[1;32m    520\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         model.optimizer.apply_gradients(zip(grads,\n\u001b[1;32m    523\u001b[0m                                             model._collected_trainable_weights))\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients)\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m         output_gradients=output_gradients)\n\u001b[0m\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients)\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m       \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       output_gradients)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    505\u001b[0m   \u001b[0muse_cudnn_on_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m   \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m   \u001b[0mshape_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m   return [\n\u001b[1;32m    509\u001b[0m       nn_ops.conv2d_backprop_input(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_n\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m    266\u001b[0m   \"\"\"\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mshape_n\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m   7328\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   7329\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ShapeN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7330\u001b[0;31m         _ctx._post_execution_callbacks, input, \"out_type\", out_type)\n\u001b[0m\u001b[1;32m   7331\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7332\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ig3rkDwv1eXl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_baseline.save_weights('baseline_80_50.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XVOvQcZzKYaZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # if running time died, please run this step after building model directly.\n",
        "# model_baseline.load_weights('baseline_80_50.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m2XBf7uBdEvw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2.1 weighted loss"
      ]
    },
    {
      "metadata": {
        "id": "kJ2yp-oQdBAK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from functools import partial, update_wrapper\n",
        "\n",
        "def wrapped_partial(func, *args, **kwargs):\n",
        "\tpartial_func = partial(func, *args, **kwargs)\n",
        "\tupdate_wrapper(partial_func, func)\n",
        "\treturn partial_func\n",
        "\n",
        "def binary_crossentropy_weigted(y_true, y_pred, class_weights):\n",
        "\ty_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n",
        "\tloss = K.mean(class_weights*(-y_true * K.log(y_pred) - (1.0 - y_true) * K.log(1.0 - y_pred)),axis=-1)\n",
        "\treturn loss\n",
        "\n",
        "custom_loss = wrapped_partial(binary_crossentropy_weigted, class_weights=np.array([1.0, 2.0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lyJz2c8Bd7R0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Step 2.2 multi-scale"
      ]
    },
    {
      "metadata": {
        "id": "UdjPJK5Td69s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### layers defination\n",
        "\n",
        "input_shape_high = (300, 300, 3)\n",
        "input_shape_low = (150, 150, 3)\n",
        "\n",
        "\n",
        "input4 = tf.keras.layers.Input(shape = input_shape_high)\n",
        "layer_level4 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape_high,\n",
        "                 padding='same')(input4)\n",
        "layer_level4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(layer_level4)\n",
        "layer_level4 = tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\n",
        "                                    activation='relu',\n",
        "                                    padding='same')(layer_level4)\n",
        "layer_level4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(layer_level4)\n",
        "\n",
        "input5 = tf.keras.layers.Input(shape = input_shape_low)\n",
        "layer_level5 = tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation = 'relu',\n",
        "                 input_shape = input_shape_low,\n",
        "                 padding = 'same')(input5)\n",
        "layer_level5 = tf.keras.layers.MaxPooling2D(pool_size = (2, 2))(layer_level5)\n",
        "layer_level5 = tf.keras.layers.Conv2D(64, kernel_size = (3, 3),\n",
        "                                    activation = 'relu',\n",
        "                                    padding = 'same')(layer_level5)\n",
        "\n",
        "added = tf.keras.layers.Add()([layer_level4, layer_level5])\n",
        "\n",
        "combine_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(added)\n",
        "combine_layer = tf.keras.layers.Flatten()(combine_layer)\n",
        "combine_layer = tf.keras.layers.Dense(128, activation ='relu')(combine_layer)\n",
        "out = tf.keras.layers.Dense(3, activation='softmax')(combine_layer)\n",
        "\n",
        "combine_model = tf.keras.models.Model(inputs=[input4, input5], outputs=out)\n",
        "\n",
        "combine_model.compile(optimizer=tf.train.RMSPropOptimizer(learning_rate=0.001),\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B_dNnKnfN9gD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Prediction for Trained Slide"
      ]
    },
    {
      "metadata": {
        "id": "2WTwD_8MfbyB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## convert labels to mask\n",
        "def label2mask(y_pred, mask_size, window_size=(150,150),center_size=(100,100),stride=100):\n",
        "  \n",
        "  mask_pred=np.zeros((mask_size[1],mask_size[0]))\n",
        "  count=0\n",
        "  x_grid=center_size[0]//2\n",
        "  y_grid=center_size[1]//2\n",
        "  for j in range(0,mask_size[0]-window_size[0],stride):    \n",
        "    for i in range(0,mask_size[1]-window_size[1],stride):  \n",
        "      x_pos=i+window_size[0]//2\n",
        "      y_pos=j+window_size[1]//2\n",
        "      if count >= len(y_pred):\n",
        "        count -= 1\n",
        "      mask_pred[(x_pos-x_grid):(x_pos+x_grid),(y_pos-y_grid):(y_pos+y_grid)]=y_pred[count]\n",
        "      count += 1\n",
        "  return(mask_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OI8ET1RhyoQl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Note: we should get all labels of slide rather than the center region here! \n",
        "# Otherwise, we would underestimate our evaluation.\n",
        "def get_test_pred(model, slide, level, window_size=(299,299),\n",
        "                     center_size=(128,128),stride=128):\n",
        "  \n",
        "  factor = int(slide.level_downsamples[level])\n",
        "  preds = []\n",
        "  for i in range(0, slide.level_dimensions[level][0]-window_size[0],stride):  \n",
        "    for j in range(0, slide.level_dimensions[level][1]-window_size[1],stride): \n",
        "      slide_img = read_slide(slide, i*factor, j*factor, level, window_size[0], window_size[1], as_float=False)\n",
        "      patches = kp_image.img_to_array(slide_img)/255\n",
        "      y_pred = model.predict(np.expand_dims(patches.astype('float32'),axis=0))\n",
        "      preds.append(y_pred)\n",
        "  \n",
        "  mask_pred = label2mask(np.asarray(preds), slide.level_dimensions[level], window_size = window_size, \n",
        "                         center_size=center_size, stride = stride)\n",
        "  return mask_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9L0QrIgEftuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mask_pred = get_test_pred(model_baseline, slide, level, window_size=window_size,\n",
        "                          center_size=center_size,stride=stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2YQqLV8KWU5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "slide_image = np.asarray(read_slide(slide, x=0, y=0, \n",
        "                         level=level, \n",
        "                         width=slide.level_dimensions[level][0], \n",
        "                         height=slide.level_dimensions[level][1]))\n",
        "mask_image = np.asarray(read_slide(tumor_mask, x=0, y=0, \n",
        "                        level=level, \n",
        "                        width=slide.level_dimensions[level][0], \n",
        "                        height=slide.level_dimensions[level][1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d8oywC7H24vc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(10,10), dpi=50)\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(slide_image)\n",
        "plt.imshow(mask_image[:,:,0],cmap='jet', alpha=0.5)\n",
        "plt.grid(False)\n",
        "plt.subplot(2,2,2)\n",
        "plt.imshow(slide_image)\n",
        "plt.imshow(mask_pred, cmap='jet',alpha=0.5) # Red regions contains cancer.\n",
        "plt.grid(False)\n",
        "plt.subplot(2,2,3)\n",
        "plt.imshow(mask_image[:,:,0])\n",
        "plt.imshow(mask_pred, cmap='jet',alpha=0.5) # Red regions contains cancer.\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q4gCF8yyyZ38",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 4: Prediction for a New Slide"
      ]
    },
    {
      "metadata": {
        "id": "t4ALhWIbys__",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Download a test slide\n",
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "fname = 'tumor_078.tif'\n",
        "if not os.path.exists(fname): \n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  f_ = drive.CreateFile({'id': '1cAFgPCkGR0zH0gqCDo4yBnstNoZmjp3C'})\n",
        "  f_.GetContentFile(fname)\n",
        "  fname = 'tumor_078_mask.tif'\n",
        "  f_ = drive.CreateFile({'id': '1ZC2urznY3gRebUG3PN2BtYD1ZPZ7GPYq'})\n",
        "  f_.GetContentFile(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V4Da20maykkd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "slide_test_path = 'tumor_078.tif'\n",
        "test_mask_path = 'tumor_078_mask.tif'\n",
        "slide_test = open_slide(slide_test_path)\n",
        "mask_test = open_slide(test_mask_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JAN2ROv-zO5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mask_pred_test = get_test_pred(model_baseline, slide_test, level, window_size=window_size,\n",
        "                               center_size=center_size,stride=stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JZKJJ6lZzfLU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "slide_test_image = np.asarray(read_slide(slide_test, x=0, y=0, \n",
        "                              level=level, \n",
        "                              width=slide_test.level_dimensions[level][0], \n",
        "                              height=slide_test.level_dimensions[level][1]))\n",
        "mask_test_image = np.asarray(read_slide(mask_test, x=0, y=0, \n",
        "                             level=level, \n",
        "                             width=slide_test.level_dimensions[level][0], \n",
        "                             height=slide_test.level_dimensions[level][1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J3OOZ0i6zZM4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plt.figure(figsize=(10,10), dpi=50)\n",
        "plt.figure(figsize=(12,10))\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(slide_test_image)\n",
        "plt.imshow(mask_test_image[:,:,0],cmap='jet', alpha=0.5)\n",
        "plt.grid(False)\n",
        "plt.subplot(2,2,2)\n",
        "plt.imshow(slide_test_image)\n",
        "plt.imshow(mask_pred_test, cmap='jet',alpha=0.5) # Red regions contains cancer.\n",
        "plt.grid(False)\n",
        "plt.subplot(2,2,3)\n",
        "plt.imshow(mask_test_image[:,:,0])\n",
        "plt.imshow(mask_pred_test, cmap='jet',alpha=0.5) # Red regions contains cancer.\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OhLnlTSsOMFn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 5: Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "Wpd0yDqKCD3d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "import sklearn\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(mask_test_image[:,:,0].reshape(-1).astype('float32'), \n",
        "                                         mask_pred_test.reshape(-1), pos_label=None)\n",
        "\n",
        "print('AUC:%s'%(metrics.auc(fpr, tpr)))\n",
        "\n",
        "plt.title('ROC curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(fpr, tpr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7OTmcRX5PfTv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "thres = thresholds[np.argmax(1-fpr+tpr)]\n",
        "mask_pred_test_labels = np.zeros(mask_pred_test.shape)\n",
        "mask_pred_test_labels[mask_pred_test > thres] = 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G7q2Ns5cPWRc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(mask_test_image[:,:,0].reshape(-1).astype('uint8'), \n",
        "                       mask_pred_test_labels.reshape(-1).astype('uint8'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "01DkXjifraYv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j5heh1T5pU4s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "recall = mat[1][1]/(mat[1][1]+mat[1][0])   #tp/tp+fn\n",
        "precision = mat[1][1]/(mat[1][1]+mat[0][1])  #tp/tp+fp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OAR8jE4ojEnQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Recall:{}'.format(recall))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FlOsPbrxjIu2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Precision:{}'.format(precision))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}